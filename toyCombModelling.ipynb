{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'data/comb_dataset'\n",
    "# dry_audio_dir = os.path.join(dataset_dir, 'input/dry')\n",
    "wet_audio_dir = os.path.join(dataset_dir, 'input/wet')\n",
    "target_dir = os.path.join(dataset_dir, 'target')\n",
    "\n",
    "audio_extension = '.wav'\n",
    "target_extension = '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dry_audio_files = [os.path.join(dry_audio_dir, filename) for filename in os.listdir(dry_audio_dir) if filename.endswith(audio_extension)]\n",
    "wet_audio_files = [os.path.join(wet_audio_dir, filename) for filename in os.listdir(wet_audio_dir) if filename.endswith(audio_extension)]\n",
    "target_files = [os.path.join(target_dir, filename) for filename in os.listdir(target_dir) if filename.endswith(target_extension)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dry_audio_files.sort()\n",
    "wet_audio_files.sort()\n",
    "target_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path):\n",
    "    audio = tf.io.read_file(file_path)\n",
    "    audio = tf.audio.decode_wav(audio, desired_channels=1).audio\n",
    "    return audio\n",
    "\n",
    "def load_target(file_path):\n",
    "    return tf.convert_to_tensor(np.load(file_path), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dry_tensors = [load_audio(file) for file in dry_audio_files]\n",
    "wet_tensors = [load_audio(file) for file in wet_audio_files]\n",
    "target_tensors = [load_target(file) for file in target_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.from_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices((dry_tensors, wet_tensors, target_tensors))\n",
    "wet_dataset = tf.data.Dataset.from_tensors(( wet_tensors))\n",
    "target_dataset = tf.data.Dataset.from_tensors((target_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorDataset element_spec=TensorSpec(shape=(50, 44100, 1), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wet_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorDataset element_spec=TensorSpec(shape=(50, 2), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wet audio shape: (50, 44100, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "num_elements = 3\n",
    "for data in wet_dataset.take(num_elements):\n",
    "    # dry_audio, wet_audio, target = data\n",
    "    wet_audio = data\n",
    "    # print(\"Dry audio shape:\", dry_audio.shape)\n",
    "    print(\"Wet audio shape:\", wet_audio.shape)\n",
    "    # print(\"Target:\", target)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: maybe different transform, potentially?\n",
    "# def mel_transform(audio):\n",
    "#   # Compute mel spectrogram using librosa\n",
    "#   mel_ = librosa.feature.melspectrogram(audio, sr=44100)\n",
    "#   # Convert mel spectrograms to logarithmic scale\n",
    "#   mel_ = librosa.power_to_db(mel_, ref=np.max)\n",
    "#   return mel_\n",
    "# # @tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n",
    "\n",
    "# def tf_mel(input):\n",
    "#   mel = tf.numpy_function(mel_transform, [input], tf.float32)\n",
    "#   return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: maybe different transform, potentially?\n",
    "def mfcc_transform(audio):\n",
    "  # Compute mel spectrogram using librosa\n",
    "  mfccs = librosa.feature.mfcc(y=audio, sr=22050, hop_length=512)\n",
    "  # Convert mel spectrograms to logarithmic scale\n",
    "#   mel_ = librosa.power_to_db(mel_, ref=np.max)\n",
    "  return mfccs\n",
    "# @tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n",
    "\n",
    "def tf_mfcc(wet, target):\n",
    "  wet = tf.numpy_function(mfcc_transform, [wet], tf.float32)\n",
    "  return wet, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=256, frame_step=128)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  # spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spec_ds(ds):\n",
    "  return ds.map(\n",
    "      map_func=lambda audio: (get_spectrogram(audio)),\n",
    "      num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ParallelMapDataset element_spec=TensorSpec(shape=(50, 44100, 0, 129), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_dataset = make_spec_ds(wet_dataset)\n",
    "spec_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wet audio shape: (50, 44100, 0, 129)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "num_elements = 3\n",
    "for data in spec_dataset.take(num_elements):\n",
    "    # dry_audio, wet_audio, target = data\n",
    "    wet_audio = data\n",
    "    # print(\"Dry audio shape:\", dry_audio.shape)\n",
    "    print(\"Wet audio shape:\", wet_audio.shape)\n",
    "    # print(\"Target:\", target)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [spec for spec in spec_dataset]\n",
    "y = [target for target in target_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.reshape(x, (50, 44100*20, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = x, y\n",
    "test_x = train_x[int(0.8 * len(train_x)):]\n",
    "test_y = train_y[int(0.8 * len(train_y)):]\n",
    "train_x = tf.stack(train_x)\n",
    "train_y = tf.stack(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_spec in spec_dataset.take(1):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = example_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (1, 50, 44100, 0, 129)\n",
      "train_y shape: (1, 50, 2)\n",
      "Reshaped train_x: (1, 0)\n",
      "Updated train_x shape: (1, 0)\n",
      "Updated train_y shape: (1, 50, 2)\n"
     ]
    }
   ],
   "source": [
    "# Verify the shapes of train_x and train_y\n",
    "print(\"train_x shape:\", train_x.shape)\n",
    "print(\"train_y shape:\", train_y.shape)\n",
    "\n",
    "# Reshape train_x if needed to match the model's input shape\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], -1))\n",
    "print(\"Reshaped train_x:\", train_x.shape)\n",
    "\n",
    "# Verify the shapes again\n",
    "print(\"Updated train_x shape:\", train_x.shape)\n",
    "print(\"Updated train_y shape:\", train_y.shape)\n",
    "\n",
    "# Define the model architecture\n",
    "# dim = train_x.shape[1:]\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=dim),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)  # Output layer for w parameter\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 50, 44100, 0, 129), found shape=(None, 0)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m      3\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_x, y\u001b[39m=\u001b[39;49mtrain_y, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n",
      "File \u001b[0;32m~/miniforge3/envs/metal/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/kt/3yzrdbd548lfc1w4yd4phlwm0000gn/T/__autograph_generated_fileopa64k5x.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 50, 44100, 0, 129), found shape=(None, 0)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 1000\n",
    "batch_size = 8\n",
    "model.fit(x=train_x, y=train_y, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
