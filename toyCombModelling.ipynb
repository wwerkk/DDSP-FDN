{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'data/toy_dataset'\n",
    "# dry_audio_dir = os.path.join(dataset_dir, 'input/dry')\n",
    "wet_audio_dir = os.path.join(dataset_dir, 'input/wet')\n",
    "target_dir = os.path.join(dataset_dir, 'target')\n",
    "\n",
    "audio_extension = '.wav'\n",
    "target_extension = '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dry_audio_files = [os.path.join(dry_audio_dir, filename) for filename in os.listdir(dry_audio_dir) if filename.endswith(audio_extension)]\n",
    "wet_audio_files = [os.path.join(wet_audio_dir, filename) for filename in os.listdir(wet_audio_dir) if filename.endswith(audio_extension)]\n",
    "target_files = [os.path.join(target_dir, filename) for filename in os.listdir(target_dir) if filename.endswith(target_extension)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dry_audio_files.sort()\n",
    "wet_audio_files.sort()\n",
    "target_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path):\n",
    "    audio = tf.io.read_file(file_path)\n",
    "    audio = tf.audio.decode_wav(audio, desired_channels=1).audio\n",
    "    return audio\n",
    "\n",
    "def load_target(file_path):\n",
    "    return tf.convert_to_tensor(np.load(file_path), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dry_tensors = [load_audio(file) for file in dry_audio_files]\n",
    "wet_tensors = [load_audio(file) for file in wet_audio_files]\n",
    "target_tensors = [load_target(file) for file in target_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices((dry_tensors, wet_tensors, target_tensors))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(( wet_tensors, target_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=(TensorSpec(shape=(44100, 1), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wet audio shape: (44100, 1)\n",
      "Target: tf.Tensor([9.340000e+02 7.374073e-01], shape=(2,), dtype=float32)\n",
      "\n",
      "Wet audio shape: (44100, 1)\n",
      "Target: tf.Tensor([344.           0.40615052], shape=(2,), dtype=float32)\n",
      "\n",
      "Wet audio shape: (44100, 1)\n",
      "Target: tf.Tensor([271.        0.87586], shape=(2,), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "num_elements = 3\n",
    "for data in dataset.take(num_elements):\n",
    "    # dry_audio, wet_audio, target = data\n",
    "    wet_audio, target = data\n",
    "    # print(\"Dry audio shape:\", dry_audio.shape)\n",
    "    print(\"Wet audio shape:\", wet_audio.shape)\n",
    "    print(\"Target:\", target)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "x, y = [], []\n",
    "for wet, target in dataset:\n",
    "    x.append(wet)\n",
    "    y.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_transform(audio):\n",
    "  # Compute mel spectrogram using librosa\n",
    "  mel_ = librosa.feature.melspectrogram(audio, sr=44100)\n",
    "  # Convert mel spectrograms to logarithmic scale\n",
    "  mel_ = librosa.power_to_db(mel_, ref=np.max)\n",
    "  return mel_\n",
    "@tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n",
    "\n",
    "def tf_mel(input):\n",
    "  mel = tf.numpy_function(mel_transform, [input], tf.float32)\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kt/3yzrdbd548lfc1w4yd4phlwm0000gn/T/ipykernel_17843/76887206.py:3: FutureWarning: Pass y=[[9.3400000e+02 7.3740733e-01]\n",
      " [3.4400000e+02 4.0615052e-01]\n",
      " [2.7100000e+02 8.7585998e-01]\n",
      " [3.4700000e+02 3.5420230e-01]\n",
      " [1.1100000e+02 6.7881894e-01]\n",
      " [8.0500000e+02 8.5378492e-01]\n",
      " [6.4700000e+02 9.6325082e-01]\n",
      " [2.0200000e+02 1.8301064e-01]\n",
      " [4.1900000e+02 7.6605016e-01]\n",
      " [4.3600000e+02 4.6521688e-01]\n",
      " [9.0900000e+02 8.1163192e-01]\n",
      " [3.7900000e+02 9.2394374e-02]\n",
      " [9.4700000e+02 5.8313626e-01]\n",
      " [8.0700000e+02 1.3723014e-02]\n",
      " [6.1300000e+02 9.6180387e-02]\n",
      " [7.0600000e+02 4.5950210e-01]\n",
      " [2.2800000e+02 6.5408722e-02]\n",
      " [9.0600000e+02 2.9620076e-02]\n",
      " [2.7700000e+02 6.9116455e-01]\n",
      " [8.3600000e+02 8.9477527e-01]\n",
      " [4.4200000e+02 8.6853641e-01]\n",
      " [1.8900000e+02 4.5626070e-02]\n",
      " [3.4600000e+02 4.2795116e-01]\n",
      " [6.7200000e+02 6.2127841e-01]\n",
      " [2.0600000e+02 2.6816574e-01]\n",
      " [1.3800000e+02 9.8963487e-01]\n",
      " [3.0600000e+02 8.4251177e-01]\n",
      " [9.5800000e+02 6.3419014e-01]\n",
      " [4.8000000e+02 4.4584569e-01]\n",
      " [5.8100000e+02 7.3946506e-01]\n",
      " [9.0300000e+02 2.8993592e-01]\n",
      " [9.0400000e+02 5.9180725e-02]\n",
      " [3.5800000e+02 5.9157729e-02]\n",
      " [1.5100000e+02 4.1865745e-01]\n",
      " [5.4200000e+02 3.2118958e-01]\n",
      " [9.3100000e+02 1.3622144e-01]\n",
      " [1.0600000e+02 5.1355195e-01]\n",
      " [6.9700000e+02 7.3596525e-01]\n",
      " [1.7600000e+02 3.4351689e-01]\n",
      " [4.5500000e+02 8.8013846e-01]\n",
      " [6.4400000e+02 1.5454391e-01]\n",
      " [4.5300000e+02 9.0660459e-01]\n",
      " [2.0000000e+02 4.7774121e-01]\n",
      " [6.6700000e+02 8.2588726e-01]\n",
      " [9.4100000e+02 5.6468529e-01]\n",
      " [8.3500000e+02 5.0508249e-01]\n",
      " [7.1200000e+02 4.0067676e-01]\n",
      " [4.0000000e+02 3.3124357e-01]\n",
      " [7.4800000e+02 2.1433692e-01]\n",
      " [9.8300000e+02 4.6859846e-01]] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_ = librosa.feature.melspectrogram(audio, sr=44100)\n",
      "/Users/wwerkowicz/miniforge3/envs/metal/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=2\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "x = [tf_mel(tensor) for tensor in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = x, y\n",
    "test_x = train_x[int(0.8 * len(train_x)):]\n",
    "test_y = train_y[int(0.8 * len(train_y)):]\n",
    "train_x = tf.stack(train_x)\n",
    "train_y = tf.stack(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (50, 50, 2)\n",
      "train_y shape: (50, 2)\n",
      "Reshaped train_x: (50, 100)\n",
      "Updated train_x shape: (50, 100)\n",
      "Updated train_y shape: (50, 2)\n"
     ]
    }
   ],
   "source": [
    "# Verify the shapes of train_x and train_y\n",
    "print(\"train_x shape:\", train_x.shape)\n",
    "print(\"train_y shape:\", train_y.shape)\n",
    "\n",
    "# Reshape train_x if needed to match the model's input shape\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], -1))\n",
    "print(\"Reshaped train_x:\", train_x.shape)\n",
    "\n",
    "# Verify the shapes again\n",
    "print(\"Updated train_x shape:\", train_x.shape)\n",
    "print(\"Updated train_y shape:\", train_y.shape)\n",
    "\n",
    "# Define the model architecture\n",
    "dim = train_x.shape[1:]\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=dim),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)  # Output layer for w parameter\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 68ms/step - loss: 129620.2031 - mae: 291.8726 - val_loss: 172535.0000 - val_mae: 362.7094\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 125511.1484 - mae: 296.7270 - val_loss: 167851.8281 - val_mae: 356.5401\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 122399.6406 - mae: 293.6154 - val_loss: 162764.4062 - val_mae: 356.8306\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 120527.6094 - mae: 294.3380 - val_loss: 160233.7969 - val_mae: 353.8568\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 118608.2734 - mae: 291.2641 - val_loss: 157946.7031 - val_mae: 350.5326\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 116659.4766 - mae: 288.2928 - val_loss: 155721.7031 - val_mae: 347.2533\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 114815.5234 - mae: 285.0876 - val_loss: 153541.9219 - val_mae: 344.0857\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 113204.9141 - mae: 283.5140 - val_loss: 149430.7812 - val_mae: 342.6796\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 110884.2500 - mae: 282.8378 - val_loss: 146551.2188 - val_mae: 339.9723\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 108987.3750 - mae: 280.9146 - val_loss: 143820.3438 - val_mae: 337.0236\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 107154.9141 - mae: 278.7163 - val_loss: 140333.0469 - val_mae: 334.4632\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 105206.2266 - mae: 276.9245 - val_loss: 138185.8750 - val_mae: 331.0045\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 103414.9609 - mae: 275.1454 - val_loss: 134347.3281 - val_mae: 328.3047\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 101257.7109 - mae: 272.8831 - val_loss: 131779.8906 - val_mae: 324.9111\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 99371.6797 - mae: 270.6967 - val_loss: 128778.2031 - val_mae: 321.6039\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 97426.7891 - mae: 268.7679 - val_loss: 125417.8516 - val_mae: 318.2582\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 95615.8281 - mae: 267.0996 - val_loss: 122652.2031 - val_mae: 314.6960\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 93680.8125 - mae: 264.8744 - val_loss: 119393.8281 - val_mae: 311.0749\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 92094.3359 - mae: 263.5274 - val_loss: 115777.2344 - val_mae: 307.2760\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 90068.6250 - mae: 260.7410 - val_loss: 113963.4531 - val_mae: 303.5844\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 88098.9922 - mae: 257.1435 - val_loss: 111971.7266 - val_mae: 299.9645\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 86714.5547 - mae: 255.4698 - val_loss: 107934.8516 - val_mae: 295.8168\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 84537.1641 - mae: 252.8597 - val_loss: 105834.8281 - val_mae: 292.1487\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 82804.7891 - mae: 249.7966 - val_loss: 103638.8203 - val_mae: 288.4719\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 81129.5234 - mae: 247.5353 - val_loss: 100633.8984 - val_mae: 284.4149\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79452.4141 - mae: 245.6259 - val_loss: 98402.7188 - val_mae: 280.6929\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 78198.1250 - mae: 243.8260 - val_loss: 94766.7969 - val_mae: 276.0699\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 76254.2109 - mae: 243.0836 - val_loss: 92241.1328 - val_mae: 272.0101\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 75230.6484 - mae: 239.9098 - val_loss: 92105.9688 - val_mae: 269.6876\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 73510.4766 - mae: 237.8484 - val_loss: 87722.3359 - val_mae: 264.1906\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 71986.1406 - mae: 237.5161 - val_loss: 85181.2422 - val_mae: 260.0426\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 70447.5156 - mae: 234.4555 - val_loss: 83892.3984 - val_mae: 256.8481\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 68952.3828 - mae: 231.4857 - val_loss: 81996.5391 - val_mae: 253.5598\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 67953.2188 - mae: 228.7736 - val_loss: 81582.8594 - val_mae: 250.9624\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66312.1875 - mae: 225.9245 - val_loss: 78558.2109 - val_mae: 247.2407\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 65109.4883 - mae: 225.4836 - val_loss: 75034.6719 - val_mae: 243.3015\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 63938.2266 - mae: 224.2117 - val_loss: 73351.5312 - val_mae: 240.0906\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 62931.5742 - mae: 222.6497 - val_loss: 71099.2266 - val_mae: 236.5263\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61612.3516 - mae: 220.2629 - val_loss: 70136.1406 - val_mae: 233.6976\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 60545.9453 - mae: 216.6024 - val_loss: 69680.2109 - val_mae: 231.2408\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 59504.6445 - mae: 214.0232 - val_loss: 68154.5469 - val_mae: 228.1850\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 58557.0000 - mae: 211.8226 - val_loss: 66413.1172 - val_mae: 224.9984\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57592.4766 - mae: 209.9121 - val_loss: 65393.5312 - val_mae: 222.3332\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 56702.1875 - mae: 208.5201 - val_loss: 63042.0430 - val_mae: 218.6645\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 55884.9570 - mae: 206.4447 - val_loss: 62179.8945 - val_mae: 216.1530\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 55005.6016 - mae: 205.2425 - val_loss: 59759.4766 - val_mae: 213.4056\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 54137.7266 - mae: 204.4015 - val_loss: 58622.8555 - val_mae: 210.8783\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 53835.0234 - mae: 204.2985 - val_loss: 56990.1680 - val_mae: 208.2220\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52718.0508 - mae: 200.7840 - val_loss: 57588.7891 - val_mae: 206.2050\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 51935.4883 - mae: 197.1799 - val_loss: 56807.3750 - val_mae: 203.8988\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 51637.1836 - mae: 194.6566 - val_loss: 56295.6016 - val_mae: 201.7607\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 50580.6797 - mae: 192.7284 - val_loss: 54904.8125 - val_mae: 199.3793\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 50202.5078 - mae: 191.3395 - val_loss: 53615.3828 - val_mae: 197.0437\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49821.1914 - mae: 192.3402 - val_loss: 50359.6797 - val_mae: 193.7621\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49144.4141 - mae: 191.0551 - val_loss: 51227.4375 - val_mae: 192.3830\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 49219.4180 - mae: 191.2036 - val_loss: 48518.1953 - val_mae: 189.1859\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 48269.4492 - mae: 187.1871 - val_loss: 50770.7500 - val_mae: 188.6645\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 47564.8008 - mae: 182.8690 - val_loss: 51428.6953 - val_mae: 187.3535\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47024.4453 - mae: 180.6321 - val_loss: 49499.2109 - val_mae: 184.7635\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46514.8086 - mae: 180.4492 - val_loss: 47763.8828 - val_mae: 182.2194\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46111.6641 - mae: 180.1939 - val_loss: 46063.4297 - val_mae: 179.6106\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46072.3438 - mae: 181.0094 - val_loss: 44579.1953 - val_mae: 177.0476\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45494.5430 - mae: 177.7167 - val_loss: 46574.4570 - val_mae: 176.9679\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45069.4414 - mae: 174.0729 - val_loss: 47225.4492 - val_mae: 175.9769\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 44676.9688 - mae: 171.9038 - val_loss: 46269.8164 - val_mae: 173.9759\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44530.5938 - mae: 172.3868 - val_loss: 43532.7305 - val_mae: 170.6200\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44205.7188 - mae: 172.7180 - val_loss: 42586.0547 - val_mae: 168.5196\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 44605.0938 - mae: 170.8853 - val_loss: 45285.6211 - val_mae: 169.3517\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43511.9883 - mae: 166.7470 - val_loss: 44104.9102 - val_mae: 167.2132\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43388.9023 - mae: 166.0842 - val_loss: 43854.7344 - val_mae: 165.8135\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43484.4453 - mae: 166.8384 - val_loss: 41076.2539 - val_mae: 162.2380\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42799.3711 - mae: 165.4952 - val_loss: 41143.1680 - val_mae: 161.1218\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42654.3984 - mae: 163.6140 - val_loss: 42060.3242 - val_mae: 160.7966\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42468.3047 - mae: 161.8123 - val_loss: 41746.5508 - val_mae: 159.3960\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42191.7266 - mae: 160.6169 - val_loss: 41144.5078 - val_mae: 157.7542\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42144.8633 - mae: 159.8816 - val_loss: 40608.2812 - val_mae: 156.1817\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41896.7305 - mae: 158.7969 - val_loss: 40940.5625 - val_mae: 155.4631\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41662.2656 - mae: 157.1282 - val_loss: 41135.6133 - val_mae: 154.6408\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41508.7578 - mae: 155.7579 - val_loss: 41064.9922 - val_mae: 153.5971\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41471.0234 - mae: 154.6189 - val_loss: 40581.6445 - val_mae: 152.1817\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41521.0703 - mae: 154.7641 - val_loss: 38774.9180 - val_mae: 149.3804\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41518.5820 - mae: 153.8901 - val_loss: 39599.6445 - val_mae: 149.3465\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41252.3984 - mae: 151.7223 - val_loss: 40873.8750 - val_mae: 149.7601\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41001.4922 - mae: 151.0702 - val_loss: 39258.6562 - val_mae: 147.2440\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41323.3984 - mae: 150.4614 - val_loss: 40850.4570 - val_mae: 148.0655\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41251.4883 - mae: 149.9413 - val_loss: 37648.5508 - val_mae: 143.7845\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40731.7617 - mae: 149.6349 - val_loss: 37456.8047 - val_mae: 142.7480\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41260.2383 - mae: 148.7421 - val_loss: 40223.0430 - val_mae: 145.0533\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40545.0234 - mae: 146.0297 - val_loss: 39745.0039 - val_mae: 143.8016\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40500.2891 - mae: 145.8383 - val_loss: 38438.0195 - val_mae: 141.6268\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40347.6016 - mae: 145.6175 - val_loss: 38123.1016 - val_mae: 140.5502\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40638.4492 - mae: 144.5341 - val_loss: 39173.2266 - val_mae: 141.0620\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40232.2734 - mae: 143.8371 - val_loss: 37809.3008 - val_mae: 138.8108\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40335.6953 - mae: 143.8990 - val_loss: 37860.4805 - val_mae: 138.2126\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40273.7070 - mae: 142.6936 - val_loss: 38210.5742 - val_mae: 137.9911\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40809.6836 - mae: 143.8286 - val_loss: 36175.8047 - val_mae: 134.8045\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40077.3828 - mae: 142.0658 - val_loss: 37084.9336 - val_mae: 135.3676\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39963.5312 - mae: 140.3626 - val_loss: 38985.7773 - val_mae: 137.0760\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40191.8555 - mae: 139.9567 - val_loss: 38350.7891 - val_mae: 135.7619\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39942.9453 - mae: 139.0966 - val_loss: 39228.7383 - val_mae: 136.2532\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40082.0742 - mae: 138.5374 - val_loss: 38185.6758 - val_mae: 134.4966\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39834.5000 - mae: 137.8316 - val_loss: 38537.2500 - val_mae: 134.4185\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39870.3203 - mae: 137.1342 - val_loss: 38849.8320 - val_mae: 134.3089\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39899.1328 - mae: 136.7783 - val_loss: 37582.9766 - val_mae: 132.2853\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39854.7578 - mae: 137.1386 - val_loss: 36641.7969 - val_mae: 130.5970\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40252.7188 - mae: 137.9583 - val_loss: 35682.5820 - val_mae: 128.8150\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39709.1484 - mae: 136.4112 - val_loss: 38070.1250 - val_mae: 131.5457\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40078.3711 - mae: 134.9974 - val_loss: 40431.5781 - val_mae: 133.9393\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39820.6680 - mae: 133.6797 - val_loss: 39234.2266 - val_mae: 132.1591\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40083.7695 - mae: 134.9369 - val_loss: 36493.3125 - val_mae: 128.2800\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39796.9688 - mae: 134.6032 - val_loss: 36858.8047 - val_mae: 128.4001\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39737.8203 - mae: 133.7811 - val_loss: 37813.2461 - val_mae: 129.2925\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39667.4883 - mae: 133.2667 - val_loss: 37339.1094 - val_mae: 128.3245\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39642.3750 - mae: 133.0056 - val_loss: 37004.0078 - val_mae: 127.5376\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39885.8047 - mae: 133.3230 - val_loss: 36176.3438 - val_mae: 126.0628\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39644.6172 - mae: 132.8079 - val_loss: 36718.6953 - val_mae: 126.4958\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39922.4492 - mae: 132.2102 - val_loss: 38307.8828 - val_mae: 128.2913\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39716.0547 - mae: 131.1160 - val_loss: 39687.1875 - val_mae: 129.7121\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39974.2344 - mae: 130.4128 - val_loss: 40525.5117 - val_mae: 130.4396\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39619.3516 - mae: 130.0649 - val_loss: 38101.9375 - val_mae: 127.2114\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39687.0859 - mae: 130.6605 - val_loss: 37584.3945 - val_mae: 126.2831\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39672.1523 - mae: 131.0180 - val_loss: 36298.8047 - val_mae: 124.2671\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40258.3477 - mae: 132.0648 - val_loss: 34611.5703 - val_mae: 121.4837\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39703.4141 - mae: 130.8011 - val_loss: 36478.0859 - val_mae: 124.0390\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39630.0000 - mae: 130.1681 - val_loss: 37206.9453 - val_mae: 124.8249\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39890.4844 - mae: 129.8698 - val_loss: 38180.8672 - val_mae: 125.9114\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39636.4297 - mae: 129.0279 - val_loss: 38333.8555 - val_mae: 125.9094\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39600.3828 - mae: 128.9693 - val_loss: 38223.6719 - val_mae: 125.5744\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39532.6289 - mae: 128.6282 - val_loss: 37540.0703 - val_mae: 124.4811\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39554.6328 - mae: 128.8238 - val_loss: 37211.7422 - val_mae: 123.8551\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39613.3086 - mae: 128.8457 - val_loss: 36574.5586 - val_mae: 122.7895\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39757.8672 - mae: 128.7760 - val_loss: 37877.4141 - val_mae: 124.4247\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39639.9297 - mae: 128.4119 - val_loss: 37035.8398 - val_mae: 123.1173\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39594.4297 - mae: 128.1147 - val_loss: 37614.1367 - val_mae: 123.7636\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39751.4922 - mae: 127.8893 - val_loss: 37770.0703 - val_mae: 123.8324\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39794.5547 - mae: 128.0974 - val_loss: 36467.5781 - val_mae: 121.8764\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39576.8438 - mae: 127.9652 - val_loss: 37082.2188 - val_mae: 122.6184\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39696.9375 - mae: 127.7745 - val_loss: 37632.2930 - val_mae: 123.2523\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39723.4531 - mae: 127.7500 - val_loss: 36660.2891 - val_mae: 121.7716\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39524.5938 - mae: 127.5741 - val_loss: 37554.0195 - val_mae: 122.9098\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39760.3398 - mae: 126.8313 - val_loss: 39254.8633 - val_mae: 125.0472\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40148.0781 - mae: 126.5505 - val_loss: 39870.2383 - val_mae: 125.7208\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39681.3281 - mae: 126.3802 - val_loss: 36754.6562 - val_mae: 121.4794\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39595.2070 - mae: 127.4393 - val_loss: 35921.8516 - val_mae: 120.1621\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40015.4453 - mae: 128.3547 - val_loss: 34772.5859 - val_mae: 118.2782\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39549.6406 - mae: 127.2863 - val_loss: 36371.2617 - val_mae: 120.6459\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39891.1641 - mae: 126.3413 - val_loss: 39461.2266 - val_mae: 124.7649\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39633.6289 - mae: 125.7238 - val_loss: 39209.5078 - val_mae: 124.3680\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39575.4141 - mae: 125.6671 - val_loss: 38956.3516 - val_mae: 123.9702\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39895.7812 - mae: 126.5032 - val_loss: 36206.0703 - val_mae: 120.0930\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40179.5195 - mae: 127.5619 - val_loss: 37820.3008 - val_mae: 122.3236\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40111.3203 - mae: 127.3269 - val_loss: 35938.2031 - val_mae: 119.5592\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39958.1953 - mae: 126.9273 - val_loss: 37698.7383 - val_mae: 122.0323\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39922.2695 - mae: 127.0437 - val_loss: 36630.9766 - val_mae: 120.4638\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39799.0547 - mae: 126.4126 - val_loss: 38550.6172 - val_mae: 123.0693\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39616.7070 - mae: 125.8497 - val_loss: 37858.8359 - val_mae: 122.0868\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39965.3711 - mae: 126.7812 - val_loss: 35992.0234 - val_mae: 119.3576\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39591.3359 - mae: 126.2070 - val_loss: 37080.6953 - val_mae: 120.9041\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39595.9766 - mae: 126.0205 - val_loss: 37844.0312 - val_mae: 121.9249\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39939.3125 - mae: 125.8052 - val_loss: 39776.4922 - val_mae: 124.4209\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39666.6680 - mae: 125.0039 - val_loss: 39120.9375 - val_mae: 123.5450\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39623.5508 - mae: 125.6712 - val_loss: 36501.9141 - val_mae: 119.9019\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39678.3750 - mae: 126.2281 - val_loss: 35217.9609 - val_mae: 117.9073\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39792.8555 - mae: 126.8021 - val_loss: 35185.7070 - val_mae: 117.8203\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39758.8164 - mae: 126.4557 - val_loss: 37722.8711 - val_mae: 121.5365\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39722.1367 - mae: 125.3953 - val_loss: 39255.3633 - val_mae: 123.5509\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39542.3359 - mae: 125.0150 - val_loss: 38215.6445 - val_mae: 122.1503\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39590.4727 - mae: 125.3325 - val_loss: 37050.4297 - val_mae: 120.5044\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39689.0977 - mae: 125.8366 - val_loss: 37187.6641 - val_mae: 120.6740\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39660.5078 - mae: 125.6713 - val_loss: 37789.6484 - val_mae: 121.4919\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39538.1562 - mae: 125.4828 - val_loss: 37398.9688 - val_mae: 120.9250\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39726.1328 - mae: 125.5766 - val_loss: 36226.4492 - val_mae: 119.2033\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39541.5742 - mae: 125.8099 - val_loss: 36506.8242 - val_mae: 119.5982\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39591.5547 - mae: 125.7251 - val_loss: 36842.6055 - val_mae: 120.0686\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39448.7422 - mae: 125.3192 - val_loss: 37867.8086 - val_mae: 121.4956\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39683.9141 - mae: 125.4498 - val_loss: 38321.1641 - val_mae: 122.0948\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39622.3047 - mae: 125.3490 - val_loss: 37571.3984 - val_mae: 121.0512\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39670.3594 - mae: 125.1902 - val_loss: 38840.7617 - val_mae: 122.7557\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39529.4609 - mae: 124.8409 - val_loss: 38076.9297 - val_mae: 121.7187\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39618.9492 - mae: 125.0331 - val_loss: 37763.8125 - val_mae: 121.2755\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39505.3711 - mae: 125.1560 - val_loss: 36946.7891 - val_mae: 120.1100\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39707.3750 - mae: 125.6074 - val_loss: 37379.0078 - val_mae: 120.7136\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39751.8672 - mae: 125.6796 - val_loss: 37873.9297 - val_mae: 121.3917\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39505.9844 - mae: 125.2554 - val_loss: 36644.5391 - val_mae: 119.6382\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39490.1758 - mae: 125.4032 - val_loss: 36705.8555 - val_mae: 119.7195\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39576.7695 - mae: 125.5443 - val_loss: 36740.3242 - val_mae: 119.7621\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39661.2109 - mae: 125.3874 - val_loss: 37203.4453 - val_mae: 120.4237\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39540.6680 - mae: 125.3363 - val_loss: 37258.0703 - val_mae: 120.4962\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39832.9805 - mae: 125.5423 - val_loss: 38700.4297 - val_mae: 122.4693\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39643.3203 - mae: 124.7038 - val_loss: 38666.6445 - val_mae: 122.4200\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39561.3867 - mae: 124.7878 - val_loss: 37865.6875 - val_mae: 121.3326\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39438.5586 - mae: 125.0714 - val_loss: 36505.5898 - val_mae: 119.3901\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40209.0117 - mae: 126.7028 - val_loss: 34001.8555 - val_mae: 115.3954\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39935.6875 - mae: 126.7202 - val_loss: 34541.5391 - val_mae: 116.3081\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39487.4141 - mae: 125.5700 - val_loss: 37284.3594 - val_mae: 120.5073\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40183.7891 - mae: 125.4891 - val_loss: 40932.7734 - val_mae: 125.2747\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39747.0000 - mae: 124.3661 - val_loss: 39696.3984 - val_mae: 123.7375\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39673.0234 - mae: 124.7632 - val_loss: 37751.4258 - val_mae: 121.1561\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39489.5117 - mae: 125.0314 - val_loss: 37249.1328 - val_mae: 120.4498\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39488.5703 - mae: 125.2988 - val_loss: 36321.5859 - val_mae: 119.0985\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39787.3984 - mae: 125.5918 - val_loss: 37582.5508 - val_mae: 120.9166\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39487.7695 - mae: 125.3751 - val_loss: 36817.1484 - val_mae: 119.8254\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39546.1523 - mae: 125.4010 - val_loss: 37347.3203 - val_mae: 120.5843\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39699.1406 - mae: 125.8818 - val_loss: 35981.1523 - val_mae: 118.5819\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39859.8828 - mae: 125.8262 - val_loss: 37412.8047 - val_mae: 120.6754\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39994.4961 - mae: 126.3178 - val_loss: 36132.8242 - val_mae: 118.8104\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39548.6016 - mae: 125.1880 - val_loss: 37798.3320 - val_mae: 121.2124\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39787.4102 - mae: 124.9246 - val_loss: 39447.4883 - val_mae: 123.4087\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39552.2891 - mae: 124.4955 - val_loss: 38575.7383 - val_mae: 122.2672\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39737.3672 - mae: 125.3128 - val_loss: 36484.3047 - val_mae: 119.3334\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39714.5195 - mae: 125.8729 - val_loss: 35771.9180 - val_mae: 118.2584\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39543.7891 - mae: 125.5134 - val_loss: 36759.7070 - val_mae: 119.7369\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40035.1016 - mae: 125.7472 - val_loss: 39352.2305 - val_mae: 123.2843\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39621.2070 - mae: 124.4692 - val_loss: 39158.6484 - val_mae: 123.0332\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39557.2031 - mae: 124.5921 - val_loss: 38239.4922 - val_mae: 121.8133\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39858.0898 - mae: 125.5584 - val_loss: 35769.0703 - val_mae: 118.2525\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39595.5742 - mae: 125.8252 - val_loss: 35659.0703 - val_mae: 118.0823\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39639.4102 - mae: 125.5397 - val_loss: 37499.0391 - val_mae: 120.7920\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39648.6172 - mae: 125.0444 - val_loss: 38864.6953 - val_mae: 122.6473\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39955.2148 - mae: 125.8174 - val_loss: 36607.0273 - val_mae: 119.5117\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39583.4922 - mae: 125.3764 - val_loss: 37684.7188 - val_mae: 121.0509\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39625.2305 - mae: 125.1699 - val_loss: 38475.6055 - val_mae: 122.1301\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39629.2109 - mae: 124.9469 - val_loss: 38300.8008 - val_mae: 121.8949\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39567.5625 - mae: 125.3282 - val_loss: 36536.1680 - val_mae: 119.4074\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39571.4453 - mae: 125.7468 - val_loss: 36060.7344 - val_mae: 118.6972\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39506.0117 - mae: 125.5332 - val_loss: 36764.2656 - val_mae: 119.7417\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39853.9766 - mae: 125.7188 - val_loss: 38720.7578 - val_mae: 122.4567\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39662.9453 - mae: 124.5995 - val_loss: 38785.5195 - val_mae: 122.5425\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39880.1797 - mae: 125.2821 - val_loss: 35958.3672 - val_mae: 118.5423\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39877.9883 - mae: 126.2501 - val_loss: 35697.4180 - val_mae: 118.1419\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39543.0625 - mae: 125.6566 - val_loss: 36764.6797 - val_mae: 119.7427\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39797.9766 - mae: 125.2854 - val_loss: 38861.8477 - val_mae: 122.6434\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39679.9805 - mae: 124.6750 - val_loss: 39399.4922 - val_mae: 123.3435\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39792.0430 - mae: 124.7407 - val_loss: 38635.8203 - val_mae: 122.3444\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39546.0859 - mae: 125.0485 - val_loss: 37121.4297 - val_mae: 120.2577\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39455.3828 - mae: 125.3835 - val_loss: 36026.5156 - val_mae: 118.6464\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39594.0000 - mae: 125.5935 - val_loss: 36454.3555 - val_mae: 119.2875\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39643.9258 - mae: 125.4923 - val_loss: 36746.8359 - val_mae: 119.7172\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39866.4297 - mae: 126.3679 - val_loss: 35782.9492 - val_mae: 118.2744\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39528.6484 - mae: 125.6359 - val_loss: 36761.9570 - val_mae: 119.7394\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39928.5703 - mae: 125.6672 - val_loss: 39293.4922 - val_mae: 123.2072\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40057.4805 - mae: 125.8242 - val_loss: 36893.2578 - val_mae: 119.9299\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39606.5625 - mae: 125.6587 - val_loss: 36451.3086 - val_mae: 119.2832\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40794.9375 - mae: 126.7066 - val_loss: 40133.5352 - val_mae: 124.2750\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39865.9375 - mae: 125.0792 - val_loss: 37688.2891 - val_mae: 121.0569\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39704.7734 - mae: 125.7348 - val_loss: 36840.6875 - val_mae: 119.8539\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39534.0664 - mae: 125.4902 - val_loss: 36622.2656 - val_mae: 119.5354\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39691.3633 - mae: 125.8093 - val_loss: 36053.9258 - val_mae: 118.6883\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39961.6758 - mae: 125.9668 - val_loss: 38419.1016 - val_mae: 122.0553\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39628.5625 - mae: 124.8302 - val_loss: 38537.2305 - val_mae: 122.2136\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39832.5859 - mae: 125.9875 - val_loss: 36933.7852 - val_mae: 119.9887\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39941.4336 - mae: 125.9305 - val_loss: 38660.5391 - val_mae: 122.3778\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39909.5820 - mae: 124.8982 - val_loss: 39398.6250 - val_mae: 123.3431\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39661.1172 - mae: 125.0633 - val_loss: 37821.8008 - val_mae: 121.2421\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39445.5117 - mae: 125.1793 - val_loss: 36605.7500 - val_mae: 119.5113\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 39685.6523 - mae: 125.8190 - val_loss: 35900.0742 - val_mae: 118.4544\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39860.2656 - mae: 126.2818 - val_loss: 35516.3828 - val_mae: 117.8614\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39555.4609 - mae: 125.6393 - val_loss: 36503.2305 - val_mae: 119.3603\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39826.6406 - mae: 125.6509 - val_loss: 38897.0703 - val_mae: 122.6906\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39589.5039 - mae: 124.5678 - val_loss: 38804.8359 - val_mae: 122.5690\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40060.6055 - mae: 126.2757 - val_loss: 36434.8008 - val_mae: 119.2590\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39601.3633 - mae: 125.6957 - val_loss: 36225.3828 - val_mae: 118.9467\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39758.5742 - mae: 125.8077 - val_loss: 38365.8125 - val_mae: 121.9837\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40024.7773 - mae: 125.9422 - val_loss: 36678.0664 - val_mae: 119.6172\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39616.6211 - mae: 125.3211 - val_loss: 37454.9453 - val_mae: 120.7310\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39637.7617 - mae: 125.0929 - val_loss: 38782.5078 - val_mae: 122.5396\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39940.1016 - mae: 125.7559 - val_loss: 37673.5078 - val_mae: 121.0366\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39540.4922 - mae: 125.2016 - val_loss: 37572.0273 - val_mae: 120.8952\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39673.1641 - mae: 125.2985 - val_loss: 38552.4805 - val_mae: 122.2341\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39809.8945 - mae: 125.6214 - val_loss: 36636.3750 - val_mae: 119.5563\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39650.8320 - mae: 125.5444 - val_loss: 36801.3320 - val_mae: 119.7971\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39523.2148 - mae: 125.4412 - val_loss: 36668.2266 - val_mae: 119.6029\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39477.7266 - mae: 125.3459 - val_loss: 37303.1797 - val_mae: 120.5170\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40268.5820 - mae: 126.3882 - val_loss: 39921.6680 - val_mae: 124.0094\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39735.2266 - mae: 124.5517 - val_loss: 38209.4180 - val_mae: 121.7725\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39787.5703 - mae: 125.5061 - val_loss: 36107.4648 - val_mae: 118.7694\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39840.6758 - mae: 125.7472 - val_loss: 37727.4492 - val_mae: 121.1115\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39771.5430 - mae: 125.8765 - val_loss: 36301.8828 - val_mae: 119.0613\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39591.1328 - mae: 125.6439 - val_loss: 36595.4922 - val_mae: 119.4963\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39720.8984 - mae: 125.7400 - val_loss: 36593.7266 - val_mae: 119.4937\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39477.2344 - mae: 125.3017 - val_loss: 37219.2695 - val_mae: 120.3979\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39753.5781 - mae: 125.3643 - val_loss: 38959.7305 - val_mae: 122.7729\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39605.1211 - mae: 124.6028 - val_loss: 38909.9141 - val_mae: 122.7076\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39529.5195 - mae: 124.8672 - val_loss: 37909.3047 - val_mae: 121.3627\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39566.3672 - mae: 125.4918 - val_loss: 36633.7695 - val_mae: 119.5525\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40159.0508 - mae: 126.0128 - val_loss: 38619.3047 - val_mae: 122.3232\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39598.2266 - mae: 125.2301 - val_loss: 37051.3398 - val_mae: 120.1580\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39736.3320 - mae: 125.7555 - val_loss: 35660.3047 - val_mae: 118.0856\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39574.2305 - mae: 125.7862 - val_loss: 35841.2578 - val_mae: 118.3645\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39735.1406 - mae: 125.8715 - val_loss: 36293.3516 - val_mae: 119.0487\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39420.3359 - mae: 125.2828 - val_loss: 37347.8203 - val_mae: 120.5801\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39574.1055 - mae: 124.6099 - val_loss: 39266.8828 - val_mae: 123.1731\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40081.0938 - mae: 125.8511 - val_loss: 37437.9219 - val_mae: 120.7071\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39504.7383 - mae: 125.1573 - val_loss: 37754.6445 - val_mae: 121.1492\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39632.8555 - mae: 125.0195 - val_loss: 38664.6680 - val_mae: 122.3835\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39660.8047 - mae: 125.0600 - val_loss: 37736.8086 - val_mae: 121.1245\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39810.6016 - mae: 125.1891 - val_loss: 38190.3359 - val_mae: 121.7465\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39462.0312 - mae: 125.0341 - val_loss: 37287.8242 - val_mae: 120.4951\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39526.2578 - mae: 125.2692 - val_loss: 37000.2188 - val_mae: 120.0847\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39835.2422 - mae: 125.8062 - val_loss: 38134.6445 - val_mae: 121.6711\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 39548.9492 - mae: 125.1876 - val_loss: 36989.7617 - val_mae: 120.0696\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40112.4922 - mae: 125.7701 - val_loss: 38641.0742 - val_mae: 122.3521\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39983.7422 - mae: 125.7957 - val_loss: 35748.8125 - val_mae: 118.2223\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39945.1133 - mae: 125.9393 - val_loss: 37188.6875 - val_mae: 120.3544\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39584.4688 - mae: 125.1541 - val_loss: 37525.2422 - val_mae: 120.8298\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39782.2734 - mae: 125.4264 - val_loss: 38377.9766 - val_mae: 122.0002\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39499.8359 - mae: 125.0398 - val_loss: 36943.4609 - val_mae: 120.0029\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39530.8047 - mae: 125.3621 - val_loss: 36620.1367 - val_mae: 119.5325\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39740.9141 - mae: 126.0493 - val_loss: 35641.6953 - val_mae: 118.0568\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39636.1758 - mae: 125.9535 - val_loss: 35908.0977 - val_mae: 118.4668\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39807.3867 - mae: 125.7415 - val_loss: 38620.0898 - val_mae: 122.3243\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39518.6484 - mae: 124.7569 - val_loss: 38486.8945 - val_mae: 122.1464\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39673.4141 - mae: 125.1787 - val_loss: 37345.8477 - val_mae: 120.5774\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39606.5703 - mae: 125.5374 - val_loss: 36773.6484 - val_mae: 119.7567\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39660.0938 - mae: 125.3896 - val_loss: 37751.2383 - val_mae: 121.1445\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39568.1875 - mae: 125.2186 - val_loss: 37487.4922 - val_mae: 120.7767\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40009.9766 - mae: 126.4148 - val_loss: 36289.0664 - val_mae: 119.0421\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40064.2539 - mae: 125.9426 - val_loss: 39358.4062 - val_mae: 123.2914\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40041.9414 - mae: 124.6205 - val_loss: 40625.2266 - val_mae: 124.8840\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39680.8125 - mae: 124.7456 - val_loss: 37574.2812 - val_mae: 120.8983\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39429.7891 - mae: 124.9855 - val_loss: 36569.0117 - val_mae: 119.4573\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39652.2578 - mae: 125.5093 - val_loss: 36923.3438 - val_mae: 119.9739\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39623.4844 - mae: 125.7346 - val_loss: 35918.4766 - val_mae: 118.4827\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39592.7617 - mae: 125.7825 - val_loss: 35876.7969 - val_mae: 118.4189\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39861.5703 - mae: 125.6106 - val_loss: 38254.6953 - val_mae: 121.8339\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39719.6133 - mae: 125.4814 - val_loss: 37071.4609 - val_mae: 120.1869\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39582.9258 - mae: 125.5433 - val_loss: 36955.9922 - val_mae: 120.0210\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39644.0820 - mae: 124.9035 - val_loss: 38441.3633 - val_mae: 122.0855\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39584.6562 - mae: 124.8297 - val_loss: 38430.6016 - val_mae: 122.0711\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40550.7266 - mae: 125.8234 - val_loss: 40178.0820 - val_mae: 124.3311\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40199.3594 - mae: 127.0346 - val_loss: 35928.2891 - val_mae: 118.4976\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39570.6367 - mae: 125.6988 - val_loss: 36293.4180 - val_mae: 119.0488\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39599.1797 - mae: 125.6168 - val_loss: 36713.8320 - val_mae: 119.6695\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39645.9609 - mae: 125.3910 - val_loss: 37651.9062 - val_mae: 121.0066\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39713.0508 - mae: 125.5636 - val_loss: 36215.1914 - val_mae: 118.9315\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39658.2461 - mae: 125.4874 - val_loss: 37401.3672 - val_mae: 120.6555\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39610.1484 - mae: 125.3433 - val_loss: 37776.3359 - val_mae: 121.1793\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39627.7578 - mae: 124.9882 - val_loss: 38316.0312 - val_mae: 121.9167\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39474.0977 - mae: 124.8136 - val_loss: 37860.3320 - val_mae: 121.2952\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39819.6875 - mae: 126.0231 - val_loss: 35809.9922 - val_mae: 118.3165\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39620.8984 - mae: 125.6376 - val_loss: 36596.2461 - val_mae: 119.4974\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39504.9141 - mae: 125.3193 - val_loss: 37373.1953 - val_mae: 120.6159\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39629.1953 - mae: 125.2896 - val_loss: 37231.9609 - val_mae: 120.4158\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39845.7812 - mae: 125.3285 - val_loss: 39033.5781 - val_mae: 122.8696\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39536.4922 - mae: 124.8312 - val_loss: 38048.2070 - val_mae: 121.5531\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39753.0234 - mae: 125.6253 - val_loss: 36256.6992 - val_mae: 118.9938\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39532.7227 - mae: 125.5350 - val_loss: 36438.5352 - val_mae: 119.2646\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39548.8516 - mae: 125.4917 - val_loss: 36558.1211 - val_mae: 119.4413\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39690.0859 - mae: 125.7812 - val_loss: 36479.5000 - val_mae: 119.3253\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40010.5859 - mae: 126.0493 - val_loss: 39235.9922 - val_mae: 123.1331\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40111.0039 - mae: 124.8513 - val_loss: 40164.2383 - val_mae: 124.3136\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39555.0391 - mae: 124.1793 - val_loss: 38777.9922 - val_mae: 122.5336\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40280.3945 - mae: 126.8607 - val_loss: 35327.8320 - val_mae: 117.5651\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39927.4141 - mae: 126.4399 - val_loss: 35302.4453 - val_mae: 117.5249\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39592.1875 - mae: 125.8266 - val_loss: 36162.2266 - val_mae: 118.8520\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39477.1250 - mae: 125.0997 - val_loss: 37886.4922 - val_mae: 121.3313\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39550.7383 - mae: 125.1529 - val_loss: 37817.9023 - val_mae: 121.2368\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39773.8867 - mae: 125.4763 - val_loss: 39160.6680 - val_mae: 123.0354\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39616.2656 - mae: 124.7182 - val_loss: 38362.5820 - val_mae: 121.9795\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39784.1250 - mae: 125.5078 - val_loss: 37044.8125 - val_mae: 120.1487\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40047.5547 - mae: 125.8260 - val_loss: 38547.7891 - val_mae: 122.2278\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39581.9023 - mae: 124.9205 - val_loss: 38269.8828 - val_mae: 121.8543\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39597.1641 - mae: 125.2843 - val_loss: 37345.0469 - val_mae: 120.5762\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39916.0938 - mae: 125.7394 - val_loss: 35814.1562 - val_mae: 118.3230\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40030.9609 - mae: 126.0667 - val_loss: 37609.1641 - val_mae: 120.9470\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39793.6367 - mae: 125.8742 - val_loss: 36328.1016 - val_mae: 119.1006\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39610.6602 - mae: 125.2912 - val_loss: 37248.0391 - val_mae: 120.4388\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40172.7617 - mae: 125.6361 - val_loss: 38845.4805 - val_mae: 122.6227\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39541.4141 - mae: 125.0262 - val_loss: 37631.2969 - val_mae: 120.9779\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39710.9766 - mae: 125.2436 - val_loss: 37588.8984 - val_mae: 120.9187\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39859.0078 - mae: 125.8123 - val_loss: 35635.4766 - val_mae: 118.0470\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39752.9180 - mae: 125.9838 - val_loss: 36655.4609 - val_mae: 119.5842\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39554.7266 - mae: 125.3442 - val_loss: 37145.1484 - val_mae: 120.2922\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39567.5234 - mae: 125.3674 - val_loss: 36813.0312 - val_mae: 119.8141\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39515.4922 - mae: 125.3473 - val_loss: 37129.2109 - val_mae: 120.2695\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39596.2734 - mae: 125.3076 - val_loss: 38183.7500 - val_mae: 121.7377\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39829.4922 - mae: 125.0732 - val_loss: 38534.0234 - val_mae: 122.2094\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39552.4883 - mae: 125.0990 - val_loss: 37217.9062 - val_mae: 120.3960\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39610.7266 - mae: 125.3780 - val_loss: 37328.4883 - val_mae: 120.5527\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39658.9805 - mae: 125.5353 - val_loss: 36165.1758 - val_mae: 118.8565\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39529.1250 - mae: 125.6110 - val_loss: 36637.1641 - val_mae: 119.5576\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39594.3984 - mae: 125.4284 - val_loss: 37397.7734 - val_mae: 120.6508\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39462.1016 - mae: 125.1007 - val_loss: 37427.5977 - val_mae: 120.6928\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39546.5625 - mae: 125.1623 - val_loss: 38117.2891 - val_mae: 121.6474\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 39511.1016 - mae: 125.1695 - val_loss: 37438.8984 - val_mae: 120.7084\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39793.0234 - mae: 125.8893 - val_loss: 36363.3867 - val_mae: 119.1530\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39675.9609 - mae: 125.7349 - val_loss: 37253.8320 - val_mae: 120.4467\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40000.5078 - mae: 125.4699 - val_loss: 38947.3984 - val_mae: 122.7565\n",
      "Epoch 389/1000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 32077.7402 - mae: 104.2057"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 1000\n",
    "batch_size = 8\n",
    "model.fit(x=train_x, y=train_y, validation_split=0.2, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
